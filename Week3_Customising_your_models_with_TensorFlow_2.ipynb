{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Week3_Customising your models with TensorFlow 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b3PNw3gJDI7",
        "hcPUtmz-JDKZ",
        "Zo5rD5ZcJDK_",
        "NrE0rpCVJDL1",
        "yrX43gwPJDL-",
        "MHcNqGnWJDMH",
        "9Ti4kMquJDML",
        "jR7y1e-xJDMd",
        "H3srEhqCJDM7"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoCorona/TensorFlow2-for-Deep-Learning/blob/main/Week3_Customising_your_models_with_TensorFlow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk88Aw4NJDIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f263374e-2909-4380-d344-4043c2a29dba"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG"
      },
      "source": [
        "# Import imdb\n",
        "import tensorflow.keras.datasets.imdb as imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jYJCwXJDJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05ad666-6fdf-46bd-b702-d9b645b27a02"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RwIt-pJDJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a8c711-16eb-4901-b883-b1f7fd185f50"
      },
      "source": [
        "# Inspect the type of the data\n",
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viryy_PDJDJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7d1b86-8de9-44da-e827-b873f6c34b6f"
      },
      "source": [
        "# Inspect the shape of the data\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6E6v-FJDJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdc16c1-a3e3-4b32-f6db-015f1e838472"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbEqyjxJDJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d5558b-a626-40f9-ae73-0245306756aa"
      },
      "source": [
        "# Display the first dataset element output\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzFxDj-JDJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f1d2e3-eaf4-4fbc-d038-9e1ffd54be7d"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "imdb.load_data(path= 'imdb.npz',\n",
        "               index_from = 3)\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGfzZg3JDJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01f5ad3-6437-4430-dfea-68326982e105"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "imdb.load_data(num_words= 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
              "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
              "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
              "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkXgUGaJDJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68525bee-0432-448e-fdd4-8cff2d108b18"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
              "         ...,\n",
              "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
              "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
              "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
              "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
              "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
              "         ...,\n",
              "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
              "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDAFt0FJDJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17eb8875-4be4-4f22-c6e5-7214acfc05f5"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "imdb.load_data(maxlen=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 13, 1228, 119, 14, 552, 7, 20, 190, 14, 58, 13, 258, 546, 1786, 8, 1968, 4, 268, 237, 13, 191, 81, 15, 13, 80, 43, 3824, 44, 12, 14, 16, 427, 3192, 4, 183, 15, 593, 19, 4, 351, 362, 26, 55, 646, 21, 4, 1239, 84, 26, 1557, 3755, 13, 244, 6, 2071, 132, 184, 194, 5, 13, 70, 4478, 546, 73, 190, 13, 62, 24, 81, 320, 4, 538, 4, 117, 250, 127, 11, 14, 20, 82, 4, 452, 11, 14, 20, 9, 8654, 19, 41, 476, 8, 4, 213, 7, 9185, 13, 657, 13, 286, 38, 1612, 44, 41, 5, 41, 1729, 88, 13, 62, 28, 900, 510, 4, 509, 51, 6, 612, 59, 16, 193, 61, 4666, 5, 702, 930, 143, 285, 25, 67, 41, 81, 366, 4, 130, 82, 9, 259, 334, 397, 1195, 7, 149, 102, 15, 26, 814, 38, 465, 1627, 31, 70, 983, 67, 51, 9, 112, 814, 17, 35, 311, 75, 26, 11649, 574, 19, 4, 1729, 23, 4, 268, 38, 95, 138, 4, 609, 191, 75, 28, 314, 1772]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 0, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-Nr897LorW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b129823-71e7-4882-9aa3-6ffcf7f99d85"
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "imdb.load_data(start_char=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkaFf6MJDJ9"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nucV40uVSRsQ",
        "outputId": "1744e4c6-1e3e-4c6e-d450-c48b97486d20"
      },
      "source": [
        "imdb_word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34701,\n",
              " 'tsukino': 52006,\n",
              " 'nunnery': 52007,\n",
              " 'sonja': 16816,\n",
              " 'vani': 63951,\n",
              " 'woods': 1408,\n",
              " 'spiders': 16115,\n",
              " 'hanging': 2345,\n",
              " 'woody': 2289,\n",
              " 'trawling': 52008,\n",
              " \"hold's\": 52009,\n",
              " 'comically': 11307,\n",
              " 'localized': 40830,\n",
              " 'disobeying': 30568,\n",
              " \"'royale\": 52010,\n",
              " \"harpo's\": 40831,\n",
              " 'canet': 52011,\n",
              " 'aileen': 19313,\n",
              " 'acurately': 52012,\n",
              " \"diplomat's\": 52013,\n",
              " 'rickman': 25242,\n",
              " 'arranged': 6746,\n",
              " 'rumbustious': 52014,\n",
              " 'familiarness': 52015,\n",
              " \"spider'\": 52016,\n",
              " 'hahahah': 68804,\n",
              " \"wood'\": 52017,\n",
              " 'transvestism': 40833,\n",
              " \"hangin'\": 34702,\n",
              " 'bringing': 2338,\n",
              " 'seamier': 40834,\n",
              " 'wooded': 34703,\n",
              " 'bravora': 52018,\n",
              " 'grueling': 16817,\n",
              " 'wooden': 1636,\n",
              " 'wednesday': 16818,\n",
              " \"'prix\": 52019,\n",
              " 'altagracia': 34704,\n",
              " 'circuitry': 52020,\n",
              " 'crotch': 11585,\n",
              " 'busybody': 57766,\n",
              " \"tart'n'tangy\": 52021,\n",
              " 'burgade': 14129,\n",
              " 'thrace': 52023,\n",
              " \"tom's\": 11038,\n",
              " 'snuggles': 52025,\n",
              " 'francesco': 29114,\n",
              " 'complainers': 52027,\n",
              " 'templarios': 52125,\n",
              " '272': 40835,\n",
              " '273': 52028,\n",
              " 'zaniacs': 52130,\n",
              " '275': 34706,\n",
              " 'consenting': 27631,\n",
              " 'snuggled': 40836,\n",
              " 'inanimate': 15492,\n",
              " 'uality': 52030,\n",
              " 'bronte': 11926,\n",
              " 'errors': 4010,\n",
              " 'dialogs': 3230,\n",
              " \"yomada's\": 52031,\n",
              " \"madman's\": 34707,\n",
              " 'dialoge': 30585,\n",
              " 'usenet': 52033,\n",
              " 'videodrome': 40837,\n",
              " \"kid'\": 26338,\n",
              " 'pawed': 52034,\n",
              " \"'girlfriend'\": 30569,\n",
              " \"'pleasure\": 52035,\n",
              " \"'reloaded'\": 52036,\n",
              " \"kazakos'\": 40839,\n",
              " 'rocque': 52037,\n",
              " 'mailings': 52038,\n",
              " 'brainwashed': 11927,\n",
              " 'mcanally': 16819,\n",
              " \"tom''\": 52039,\n",
              " 'kurupt': 25243,\n",
              " 'affiliated': 21905,\n",
              " 'babaganoosh': 52040,\n",
              " \"noe's\": 40840,\n",
              " 'quart': 40841,\n",
              " 'kids': 359,\n",
              " 'uplifting': 5034,\n",
              " 'controversy': 7093,\n",
              " 'kida': 21906,\n",
              " 'kidd': 23379,\n",
              " \"error'\": 52041,\n",
              " 'neurologist': 52042,\n",
              " 'spotty': 18510,\n",
              " 'cobblers': 30570,\n",
              " 'projection': 9878,\n",
              " 'fastforwarding': 40842,\n",
              " 'sters': 52043,\n",
              " \"eggar's\": 52044,\n",
              " 'etherything': 52045,\n",
              " 'gateshead': 40843,\n",
              " 'airball': 34708,\n",
              " 'unsinkable': 25244,\n",
              " 'stern': 7180,\n",
              " \"cervi's\": 52046,\n",
              " 'dnd': 40844,\n",
              " 'dna': 11586,\n",
              " 'insecurity': 20598,\n",
              " \"'reboot'\": 52047,\n",
              " 'trelkovsky': 11037,\n",
              " 'jaekel': 52048,\n",
              " 'sidebars': 52049,\n",
              " \"sforza's\": 52050,\n",
              " 'distortions': 17633,\n",
              " 'mutinies': 52051,\n",
              " 'sermons': 30602,\n",
              " '7ft': 40846,\n",
              " 'boobage': 52052,\n",
              " \"o'bannon's\": 52053,\n",
              " 'populations': 23380,\n",
              " 'chulak': 52054,\n",
              " 'mesmerize': 27633,\n",
              " 'quinnell': 52055,\n",
              " 'yahoo': 10307,\n",
              " 'meteorologist': 52057,\n",
              " 'beswick': 42577,\n",
              " 'boorman': 15493,\n",
              " 'voicework': 40847,\n",
              " \"ster'\": 52058,\n",
              " 'blustering': 22922,\n",
              " 'hj': 52059,\n",
              " 'intake': 27634,\n",
              " 'morally': 5621,\n",
              " 'jumbling': 40849,\n",
              " 'bowersock': 52060,\n",
              " \"'porky's'\": 52061,\n",
              " 'gershon': 16821,\n",
              " 'ludicrosity': 40850,\n",
              " 'coprophilia': 52062,\n",
              " 'expressively': 40851,\n",
              " \"india's\": 19500,\n",
              " \"post's\": 34710,\n",
              " 'wana': 52063,\n",
              " 'wang': 5283,\n",
              " 'wand': 30571,\n",
              " 'wane': 25245,\n",
              " 'edgeways': 52321,\n",
              " 'titanium': 34711,\n",
              " 'pinta': 40852,\n",
              " 'want': 178,\n",
              " 'pinto': 30572,\n",
              " 'whoopdedoodles': 52065,\n",
              " 'tchaikovsky': 21908,\n",
              " 'travel': 2103,\n",
              " \"'victory'\": 52066,\n",
              " 'copious': 11928,\n",
              " 'gouge': 22433,\n",
              " \"chapters'\": 52067,\n",
              " 'barbra': 6702,\n",
              " 'uselessness': 30573,\n",
              " \"wan'\": 52068,\n",
              " 'assimilated': 27635,\n",
              " 'petiot': 16116,\n",
              " 'most\\x85and': 52069,\n",
              " 'dinosaurs': 3930,\n",
              " 'wrong': 352,\n",
              " 'seda': 52070,\n",
              " 'stollen': 52071,\n",
              " 'sentencing': 34712,\n",
              " 'ouroboros': 40853,\n",
              " 'assimilates': 40854,\n",
              " 'colorfully': 40855,\n",
              " 'glenne': 27636,\n",
              " 'dongen': 52072,\n",
              " 'subplots': 4760,\n",
              " 'kiloton': 52073,\n",
              " 'chandon': 23381,\n",
              " \"effect'\": 34713,\n",
              " 'snugly': 27637,\n",
              " 'kuei': 40856,\n",
              " 'welcomed': 9092,\n",
              " 'dishonor': 30071,\n",
              " 'concurrence': 52075,\n",
              " 'stoicism': 23382,\n",
              " \"guys'\": 14896,\n",
              " \"beroemd'\": 52077,\n",
              " 'butcher': 6703,\n",
              " \"melfi's\": 40857,\n",
              " 'aargh': 30623,\n",
              " 'playhouse': 20599,\n",
              " 'wickedly': 11308,\n",
              " 'fit': 1180,\n",
              " 'labratory': 52078,\n",
              " 'lifeline': 40859,\n",
              " 'screaming': 1927,\n",
              " 'fix': 4287,\n",
              " 'cineliterate': 52079,\n",
              " 'fic': 52080,\n",
              " 'fia': 52081,\n",
              " 'fig': 34714,\n",
              " 'fmvs': 52082,\n",
              " 'fie': 52083,\n",
              " 'reentered': 52084,\n",
              " 'fin': 30574,\n",
              " 'doctresses': 52085,\n",
              " 'fil': 52086,\n",
              " 'zucker': 12606,\n",
              " 'ached': 31931,\n",
              " 'counsil': 52088,\n",
              " 'paterfamilias': 52089,\n",
              " 'songwriter': 13885,\n",
              " 'shivam': 34715,\n",
              " 'hurting': 9654,\n",
              " 'effects': 299,\n",
              " 'slauther': 52090,\n",
              " \"'flame'\": 52091,\n",
              " 'sommerset': 52092,\n",
              " 'interwhined': 52093,\n",
              " 'whacking': 27638,\n",
              " 'bartok': 52094,\n",
              " 'barton': 8775,\n",
              " 'frewer': 21909,\n",
              " \"fi'\": 52095,\n",
              " 'ingrid': 6192,\n",
              " 'stribor': 30575,\n",
              " 'approporiately': 52096,\n",
              " 'wobblyhand': 52097,\n",
              " 'tantalisingly': 52098,\n",
              " 'ankylosaurus': 52099,\n",
              " 'parasites': 17634,\n",
              " 'childen': 52100,\n",
              " \"jenkins'\": 52101,\n",
              " 'metafiction': 52102,\n",
              " 'golem': 17635,\n",
              " 'indiscretion': 40860,\n",
              " \"reeves'\": 23383,\n",
              " \"inamorata's\": 57781,\n",
              " 'brittannica': 52104,\n",
              " 'adapt': 7916,\n",
              " \"russo's\": 30576,\n",
              " 'guitarists': 48246,\n",
              " 'abbott': 10553,\n",
              " 'abbots': 40861,\n",
              " 'lanisha': 17649,\n",
              " 'magickal': 40863,\n",
              " 'mattter': 52105,\n",
              " \"'willy\": 52106,\n",
              " 'pumpkins': 34716,\n",
              " 'stuntpeople': 52107,\n",
              " 'estimate': 30577,\n",
              " 'ugghhh': 40864,\n",
              " 'gameplay': 11309,\n",
              " \"wern't\": 52108,\n",
              " \"n'sync\": 40865,\n",
              " 'sickeningly': 16117,\n",
              " 'chiara': 40866,\n",
              " 'disturbed': 4011,\n",
              " 'portmanteau': 40867,\n",
              " 'ineffectively': 52109,\n",
              " \"duchonvey's\": 82143,\n",
              " \"nasty'\": 37519,\n",
              " 'purpose': 1285,\n",
              " 'lazers': 52112,\n",
              " 'lightened': 28105,\n",
              " 'kaliganj': 52113,\n",
              " 'popularism': 52114,\n",
              " \"damme's\": 18511,\n",
              " 'stylistics': 30578,\n",
              " 'mindgaming': 52115,\n",
              " 'spoilerish': 46449,\n",
              " \"'corny'\": 52117,\n",
              " 'boerner': 34718,\n",
              " 'olds': 6792,\n",
              " 'bakelite': 52118,\n",
              " 'renovated': 27639,\n",
              " 'forrester': 27640,\n",
              " \"lumiere's\": 52119,\n",
              " 'gaskets': 52024,\n",
              " 'needed': 884,\n",
              " 'smight': 34719,\n",
              " 'master': 1297,\n",
              " \"edie's\": 25905,\n",
              " 'seeber': 40868,\n",
              " 'hiya': 52120,\n",
              " 'fuzziness': 52121,\n",
              " 'genesis': 14897,\n",
              " 'rewards': 12607,\n",
              " 'enthrall': 30579,\n",
              " \"'about\": 40869,\n",
              " \"recollection's\": 52122,\n",
              " 'mutilated': 11039,\n",
              " 'fatherlands': 52123,\n",
              " \"fischer's\": 52124,\n",
              " 'positively': 5399,\n",
              " '270': 34705,\n",
              " 'ahmed': 34720,\n",
              " 'zatoichi': 9836,\n",
              " 'bannister': 13886,\n",
              " 'anniversaries': 52127,\n",
              " \"helm's\": 30580,\n",
              " \"'work'\": 52128,\n",
              " 'exclaimed': 34721,\n",
              " \"'unfunny'\": 52129,\n",
              " '274': 52029,\n",
              " 'feeling': 544,\n",
              " \"wanda's\": 52131,\n",
              " 'dolan': 33266,\n",
              " '278': 52133,\n",
              " 'peacoat': 52134,\n",
              " 'brawny': 40870,\n",
              " 'mishra': 40871,\n",
              " 'worlders': 40872,\n",
              " 'protags': 52135,\n",
              " 'skullcap': 52136,\n",
              " 'dastagir': 57596,\n",
              " 'affairs': 5622,\n",
              " 'wholesome': 7799,\n",
              " 'hymen': 52137,\n",
              " 'paramedics': 25246,\n",
              " 'unpersons': 52138,\n",
              " 'heavyarms': 52139,\n",
              " 'affaire': 52140,\n",
              " 'coulisses': 52141,\n",
              " 'hymer': 40873,\n",
              " 'kremlin': 52142,\n",
              " 'shipments': 30581,\n",
              " 'pixilated': 52143,\n",
              " \"'00s\": 30582,\n",
              " 'diminishing': 18512,\n",
              " 'cinematic': 1357,\n",
              " 'resonates': 14898,\n",
              " 'simplify': 40874,\n",
              " \"nature'\": 40875,\n",
              " 'temptresses': 40876,\n",
              " 'reverence': 16822,\n",
              " 'resonated': 19502,\n",
              " 'dailey': 34722,\n",
              " '2\\x85': 52144,\n",
              " 'treize': 27641,\n",
              " 'majo': 52145,\n",
              " 'kiya': 21910,\n",
              " 'woolnough': 52146,\n",
              " 'thanatos': 39797,\n",
              " 'sandoval': 35731,\n",
              " 'dorama': 40879,\n",
              " \"o'shaughnessy\": 52147,\n",
              " 'tech': 4988,\n",
              " 'fugitives': 32018,\n",
              " 'teck': 30583,\n",
              " \"'e'\": 76125,\n",
              " 'doesn’t': 40881,\n",
              " 'purged': 52149,\n",
              " 'saying': 657,\n",
              " \"martians'\": 41095,\n",
              " 'norliss': 23418,\n",
              " 'dickey': 27642,\n",
              " 'dicker': 52152,\n",
              " \"'sependipity\": 52153,\n",
              " 'padded': 8422,\n",
              " 'ordell': 57792,\n",
              " \"sturges'\": 40882,\n",
              " 'independentcritics': 52154,\n",
              " 'tempted': 5745,\n",
              " \"atkinson's\": 34724,\n",
              " 'hounded': 25247,\n",
              " 'apace': 52155,\n",
              " 'clicked': 15494,\n",
              " \"'humor'\": 30584,\n",
              " \"martino's\": 17177,\n",
              " \"'supporting\": 52156,\n",
              " 'warmongering': 52032,\n",
              " \"zemeckis's\": 34725,\n",
              " 'lube': 21911,\n",
              " 'shocky': 52157,\n",
              " 'plate': 7476,\n",
              " 'plata': 40883,\n",
              " 'sturgess': 40884,\n",
              " \"nerds'\": 40885,\n",
              " 'plato': 20600,\n",
              " 'plath': 34726,\n",
              " 'platt': 40886,\n",
              " 'mcnab': 52159,\n",
              " 'clumsiness': 27643,\n",
              " 'altogether': 3899,\n",
              " 'massacring': 42584,\n",
              " 'bicenntinial': 52160,\n",
              " 'skaal': 40887,\n",
              " 'droning': 14360,\n",
              " 'lds': 8776,\n",
              " 'jaguar': 21912,\n",
              " \"cale's\": 34727,\n",
              " 'nicely': 1777,\n",
              " 'mummy': 4588,\n",
              " \"lot's\": 18513,\n",
              " 'patch': 10086,\n",
              " 'kerkhof': 50202,\n",
              " \"leader's\": 52161,\n",
              " \"'movie\": 27644,\n",
              " 'uncomfirmed': 52162,\n",
              " 'heirloom': 40888,\n",
              " 'wrangle': 47360,\n",
              " 'emotion\\x85': 52163,\n",
              " \"'stargate'\": 52164,\n",
              " 'pinoy': 40889,\n",
              " 'conchatta': 40890,\n",
              " 'broeke': 41128,\n",
              " 'advisedly': 40891,\n",
              " \"barker's\": 17636,\n",
              " 'descours': 52166,\n",
              " 'lots': 772,\n",
              " 'lotr': 9259,\n",
              " 'irs': 9879,\n",
              " 'lott': 52167,\n",
              " 'xvi': 40892,\n",
              " 'irk': 34728,\n",
              " 'irl': 52168,\n",
              " 'ira': 6887,\n",
              " 'belzer': 21913,\n",
              " 'irc': 52169,\n",
              " 'ire': 27645,\n",
              " 'requisites': 40893,\n",
              " 'discipline': 7693,\n",
              " 'lyoko': 52961,\n",
              " 'extend': 11310,\n",
              " 'nature': 873,\n",
              " \"'dickie'\": 52170,\n",
              " 'optimist': 40894,\n",
              " 'lapping': 30586,\n",
              " 'superficial': 3900,\n",
              " 'vestment': 52171,\n",
              " 'extent': 2823,\n",
              " 'tendons': 52172,\n",
              " \"heller's\": 52173,\n",
              " 'quagmires': 52174,\n",
              " 'miyako': 52175,\n",
              " 'moocow': 20601,\n",
              " \"coles'\": 52176,\n",
              " 'lookit': 40895,\n",
              " 'ravenously': 52177,\n",
              " 'levitating': 40896,\n",
              " 'perfunctorily': 52178,\n",
              " 'lookin': 30587,\n",
              " \"lot'\": 40898,\n",
              " 'lookie': 52179,\n",
              " 'fearlessly': 34870,\n",
              " 'libyan': 52181,\n",
              " 'fondles': 40899,\n",
              " 'gopher': 35714,\n",
              " 'wearying': 40901,\n",
              " \"nz's\": 52182,\n",
              " 'minuses': 27646,\n",
              " 'puposelessly': 52183,\n",
              " 'shandling': 52184,\n",
              " 'decapitates': 31268,\n",
              " 'humming': 11929,\n",
              " \"'nother\": 40902,\n",
              " 'smackdown': 21914,\n",
              " 'underdone': 30588,\n",
              " 'frf': 40903,\n",
              " 'triviality': 52185,\n",
              " 'fro': 25248,\n",
              " 'bothers': 8777,\n",
              " \"'kensington\": 52186,\n",
              " 'much': 73,\n",
              " 'muco': 34730,\n",
              " 'wiseguy': 22615,\n",
              " \"richie's\": 27648,\n",
              " 'tonino': 40904,\n",
              " 'unleavened': 52187,\n",
              " 'fry': 11587,\n",
              " \"'tv'\": 40905,\n",
              " 'toning': 40906,\n",
              " 'obese': 14361,\n",
              " 'sensationalized': 30589,\n",
              " 'spiv': 40907,\n",
              " 'spit': 6259,\n",
              " 'arkin': 7364,\n",
              " 'charleton': 21915,\n",
              " 'jeon': 16823,\n",
              " 'boardroom': 21916,\n",
              " 'doubts': 4989,\n",
              " 'spin': 3084,\n",
              " 'hepo': 53083,\n",
              " 'wildcat': 27649,\n",
              " 'venoms': 10584,\n",
              " 'misconstrues': 52191,\n",
              " 'mesmerising': 18514,\n",
              " 'misconstrued': 40908,\n",
              " 'rescinds': 52192,\n",
              " 'prostrate': 52193,\n",
              " 'majid': 40909,\n",
              " 'climbed': 16479,\n",
              " 'canoeing': 34731,\n",
              " 'majin': 52195,\n",
              " 'animie': 57804,\n",
              " 'sylke': 40910,\n",
              " 'conditioned': 14899,\n",
              " 'waddell': 40911,\n",
              " '3\\x85': 52196,\n",
              " 'hyperdrive': 41188,\n",
              " 'conditioner': 34732,\n",
              " 'bricklayer': 53153,\n",
              " 'hong': 2576,\n",
              " 'memoriam': 52198,\n",
              " 'inventively': 30592,\n",
              " \"levant's\": 25249,\n",
              " 'portobello': 20638,\n",
              " 'remand': 52200,\n",
              " 'mummified': 19504,\n",
              " 'honk': 27650,\n",
              " 'spews': 19505,\n",
              " 'visitations': 40912,\n",
              " 'mummifies': 52201,\n",
              " 'cavanaugh': 25250,\n",
              " 'zeon': 23385,\n",
              " \"jungle's\": 40913,\n",
              " 'viertel': 34733,\n",
              " 'frenchmen': 27651,\n",
              " 'torpedoes': 52202,\n",
              " 'schlessinger': 52203,\n",
              " 'torpedoed': 34734,\n",
              " 'blister': 69876,\n",
              " 'cinefest': 52204,\n",
              " 'furlough': 34735,\n",
              " 'mainsequence': 52205,\n",
              " 'mentors': 40914,\n",
              " 'academic': 9094,\n",
              " 'stillness': 20602,\n",
              " 'academia': 40915,\n",
              " 'lonelier': 52206,\n",
              " 'nibby': 52207,\n",
              " \"losers'\": 52208,\n",
              " 'cineastes': 40916,\n",
              " 'corporate': 4449,\n",
              " 'massaging': 40917,\n",
              " 'bellow': 30593,\n",
              " 'absurdities': 19506,\n",
              " 'expetations': 53241,\n",
              " 'nyfiken': 40918,\n",
              " 'mehras': 75638,\n",
              " 'lasse': 52209,\n",
              " 'visability': 52210,\n",
              " 'militarily': 33946,\n",
              " \"elder'\": 52211,\n",
              " 'gainsbourg': 19023,\n",
              " 'hah': 20603,\n",
              " 'hai': 13420,\n",
              " 'haj': 34736,\n",
              " 'hak': 25251,\n",
              " 'hal': 4311,\n",
              " 'ham': 4892,\n",
              " 'duffer': 53259,\n",
              " 'haa': 52213,\n",
              " 'had': 66,\n",
              " 'advancement': 11930,\n",
              " 'hag': 16825,\n",
              " \"hand'\": 25252,\n",
              " 'hay': 13421,\n",
              " 'mcnamara': 20604,\n",
              " \"mozart's\": 52214,\n",
              " 'duffel': 30731,\n",
              " 'haq': 30594,\n",
              " 'har': 13887,\n",
              " 'has': 44,\n",
              " 'hat': 2401,\n",
              " 'hav': 40919,\n",
              " 'haw': 30595,\n",
              " 'figtings': 52215,\n",
              " 'elders': 15495,\n",
              " 'underpanted': 52216,\n",
              " 'pninson': 52217,\n",
              " 'unequivocally': 27652,\n",
              " \"barbara's\": 23673,\n",
              " \"bello'\": 52219,\n",
              " 'indicative': 12997,\n",
              " 'yawnfest': 40920,\n",
              " 'hexploitation': 52220,\n",
              " \"loder's\": 52221,\n",
              " 'sleuthing': 27653,\n",
              " \"justin's\": 32622,\n",
              " \"'ball\": 52222,\n",
              " \"'summer\": 52223,\n",
              " \"'demons'\": 34935,\n",
              " \"mormon's\": 52225,\n",
              " \"laughton's\": 34737,\n",
              " 'debell': 52226,\n",
              " 'shipyard': 39724,\n",
              " 'unabashedly': 30597,\n",
              " 'disks': 40401,\n",
              " 'crowd': 2290,\n",
              " 'crowe': 10087,\n",
              " \"vancouver's\": 56434,\n",
              " 'mosques': 34738,\n",
              " 'crown': 6627,\n",
              " 'culpas': 52227,\n",
              " 'crows': 27654,\n",
              " 'surrell': 53344,\n",
              " 'flowless': 52229,\n",
              " 'sheirk': 52230,\n",
              " \"'three\": 40923,\n",
              " \"peterson'\": 52231,\n",
              " 'ooverall': 52232,\n",
              " 'perchance': 40924,\n",
              " 'bottom': 1321,\n",
              " 'chabert': 53363,\n",
              " 'sneha': 52233,\n",
              " 'inhuman': 13888,\n",
              " 'ichii': 52234,\n",
              " 'ursla': 52235,\n",
              " 'completly': 30598,\n",
              " 'moviedom': 40925,\n",
              " 'raddick': 52236,\n",
              " 'brundage': 51995,\n",
              " 'brigades': 40926,\n",
              " 'starring': 1181,\n",
              " \"'goal'\": 52237,\n",
              " 'caskets': 52238,\n",
              " 'willcock': 52239,\n",
              " \"threesome's\": 52240,\n",
              " \"mosque'\": 52241,\n",
              " \"cover's\": 52242,\n",
              " 'spaceships': 17637,\n",
              " 'anomalous': 40927,\n",
              " 'ptsd': 27655,\n",
              " 'shirdan': 52243,\n",
              " 'obscenity': 21962,\n",
              " 'lemmings': 30599,\n",
              " 'duccio': 30600,\n",
              " \"levene's\": 52244,\n",
              " \"'gorby'\": 52245,\n",
              " \"teenager's\": 25255,\n",
              " 'marshall': 5340,\n",
              " 'honeymoon': 9095,\n",
              " 'shoots': 3231,\n",
              " 'despised': 12258,\n",
              " 'okabasho': 52246,\n",
              " 'fabric': 8289,\n",
              " 'cannavale': 18515,\n",
              " 'raped': 3537,\n",
              " \"tutt's\": 52247,\n",
              " 'grasping': 17638,\n",
              " 'despises': 18516,\n",
              " \"thief's\": 40928,\n",
              " 'rapes': 8926,\n",
              " 'raper': 52248,\n",
              " \"eyre'\": 27656,\n",
              " 'walchek': 52249,\n",
              " \"elmo's\": 23386,\n",
              " 'perfumes': 40929,\n",
              " 'spurting': 21918,\n",
              " \"exposition'\\x85\": 52250,\n",
              " 'denoting': 52251,\n",
              " 'thesaurus': 34740,\n",
              " \"shoot'\": 40930,\n",
              " 'bonejack': 49759,\n",
              " 'simpsonian': 52253,\n",
              " 'hebetude': 30601,\n",
              " \"hallow's\": 34741,\n",
              " 'desperation\\x85': 52254,\n",
              " 'incinerator': 34742,\n",
              " 'congratulations': 10308,\n",
              " 'humbled': 52255,\n",
              " \"else's\": 5924,\n",
              " 'trelkovski': 40845,\n",
              " \"rape'\": 52256,\n",
              " \"'chapters'\": 59386,\n",
              " '1600s': 52257,\n",
              " 'martian': 7253,\n",
              " 'nicest': 25256,\n",
              " 'eyred': 52259,\n",
              " 'passenger': 9457,\n",
              " 'disgrace': 6041,\n",
              " 'moderne': 52260,\n",
              " 'barrymore': 5120,\n",
              " 'yankovich': 52261,\n",
              " 'moderns': 40931,\n",
              " 'studliest': 52262,\n",
              " 'bedsheet': 52263,\n",
              " 'decapitation': 14900,\n",
              " 'slurring': 52264,\n",
              " \"'nunsploitation'\": 52265,\n",
              " \"'character'\": 34743,\n",
              " 'cambodia': 9880,\n",
              " 'rebelious': 52266,\n",
              " 'pasadena': 27657,\n",
              " 'crowne': 40932,\n",
              " \"'bedchamber\": 52267,\n",
              " 'conjectural': 52268,\n",
              " 'appologize': 52269,\n",
              " 'halfassing': 52270,\n",
              " 'paycheque': 57816,\n",
              " 'palms': 20606,\n",
              " \"'islands\": 52271,\n",
              " 'hawked': 40933,\n",
              " 'palme': 21919,\n",
              " 'conservatively': 40934,\n",
              " 'larp': 64007,\n",
              " 'palma': 5558,\n",
              " 'smelling': 21920,\n",
              " 'aragorn': 12998,\n",
              " 'hawker': 52272,\n",
              " 'hawkes': 52273,\n",
              " 'explosions': 3975,\n",
              " 'loren': 8059,\n",
              " \"pyle's\": 52274,\n",
              " 'shootout': 6704,\n",
              " \"mike's\": 18517,\n",
              " \"driscoll's\": 52275,\n",
              " 'cogsworth': 40935,\n",
              " \"britian's\": 52276,\n",
              " 'childs': 34744,\n",
              " \"portrait's\": 52277,\n",
              " 'chain': 3626,\n",
              " 'whoever': 2497,\n",
              " 'puttered': 52278,\n",
              " 'childe': 52279,\n",
              " 'maywether': 52280,\n",
              " 'chair': 3036,\n",
              " \"rance's\": 52281,\n",
              " 'machu': 34745,\n",
              " 'ballet': 4517,\n",
              " 'grapples': 34746,\n",
              " 'summerize': 76152,\n",
              " 'freelance': 30603,\n",
              " \"andrea's\": 52283,\n",
              " '\\x91very': 52284,\n",
              " 'coolidge': 45879,\n",
              " 'mache': 18518,\n",
              " 'balled': 52285,\n",
              " 'grappled': 40937,\n",
              " 'macha': 18519,\n",
              " 'underlining': 21921,\n",
              " 'macho': 5623,\n",
              " 'oversight': 19507,\n",
              " 'machi': 25257,\n",
              " 'verbally': 11311,\n",
              " 'tenacious': 21922,\n",
              " 'windshields': 40938,\n",
              " 'paychecks': 18557,\n",
              " 'jerk': 3396,\n",
              " \"good'\": 11931,\n",
              " 'prancer': 34748,\n",
              " 'prances': 21923,\n",
              " 'olympus': 52286,\n",
              " 'lark': 21924,\n",
              " 'embark': 10785,\n",
              " 'gloomy': 7365,\n",
              " 'jehaan': 52287,\n",
              " 'turaqui': 52288,\n",
              " \"child'\": 20607,\n",
              " 'locked': 2894,\n",
              " 'pranced': 52289,\n",
              " 'exact': 2588,\n",
              " 'unattuned': 52290,\n",
              " 'minute': 783,\n",
              " 'skewed': 16118,\n",
              " 'hodgins': 40940,\n",
              " 'skewer': 34749,\n",
              " 'think\\x85': 52291,\n",
              " 'rosenstein': 38765,\n",
              " 'helmit': 52292,\n",
              " 'wrestlemanias': 34750,\n",
              " 'hindered': 16826,\n",
              " \"martha's\": 30604,\n",
              " 'cheree': 52293,\n",
              " \"pluckin'\": 52294,\n",
              " 'ogles': 40941,\n",
              " 'heavyweight': 11932,\n",
              " 'aada': 82190,\n",
              " 'chopping': 11312,\n",
              " 'strongboy': 61534,\n",
              " 'hegemonic': 41342,\n",
              " 'adorns': 40942,\n",
              " 'xxth': 41346,\n",
              " 'nobuhiro': 34751,\n",
              " 'capitães': 52298,\n",
              " 'kavogianni': 52299,\n",
              " 'antwerp': 13422,\n",
              " 'celebrated': 6538,\n",
              " 'roarke': 52300,\n",
              " 'baggins': 40943,\n",
              " 'cheeseburgers': 31270,\n",
              " 'matras': 52301,\n",
              " \"nineties'\": 52302,\n",
              " \"'craig'\": 52303,\n",
              " 'celebrates': 12999,\n",
              " 'unintentionally': 3383,\n",
              " 'drafted': 14362,\n",
              " 'climby': 52304,\n",
              " '303': 52305,\n",
              " 'oldies': 18520,\n",
              " 'climbs': 9096,\n",
              " 'honour': 9655,\n",
              " 'plucking': 34752,\n",
              " '305': 30074,\n",
              " 'address': 5514,\n",
              " 'menjou': 40944,\n",
              " \"'freak'\": 42592,\n",
              " 'dwindling': 19508,\n",
              " 'benson': 9458,\n",
              " 'white’s': 52307,\n",
              " 'shamelessness': 40945,\n",
              " 'impacted': 21925,\n",
              " 'upatz': 52308,\n",
              " 'cusack': 3840,\n",
              " \"flavia's\": 37567,\n",
              " 'effette': 52309,\n",
              " 'influx': 34753,\n",
              " 'boooooooo': 52310,\n",
              " 'dimitrova': 52311,\n",
              " 'houseman': 13423,\n",
              " 'bigas': 25259,\n",
              " 'boylen': 52312,\n",
              " 'phillipenes': 52313,\n",
              " 'fakery': 40946,\n",
              " \"grandpa's\": 27658,\n",
              " 'darnell': 27659,\n",
              " 'undergone': 19509,\n",
              " 'handbags': 52315,\n",
              " 'perished': 21926,\n",
              " 'pooped': 37778,\n",
              " 'vigour': 27660,\n",
              " 'opposed': 3627,\n",
              " 'etude': 52316,\n",
              " \"caine's\": 11799,\n",
              " 'doozers': 52317,\n",
              " 'photojournals': 34754,\n",
              " 'perishes': 52318,\n",
              " 'constrains': 34755,\n",
              " 'migenes': 40948,\n",
              " 'consoled': 30605,\n",
              " 'alastair': 16827,\n",
              " 'wvs': 52319,\n",
              " 'ooooooh': 52320,\n",
              " 'approving': 34756,\n",
              " 'consoles': 40949,\n",
              " 'disparagement': 52064,\n",
              " 'futureistic': 52322,\n",
              " 'rebounding': 52323,\n",
              " \"'date\": 52324,\n",
              " 'gregoire': 52325,\n",
              " 'rutherford': 21927,\n",
              " 'americanised': 34757,\n",
              " 'novikov': 82196,\n",
              " 'following': 1042,\n",
              " 'munroe': 34758,\n",
              " \"morita'\": 52326,\n",
              " 'christenssen': 52327,\n",
              " 'oatmeal': 23106,\n",
              " 'fossey': 25260,\n",
              " 'livered': 40950,\n",
              " 'listens': 13000,\n",
              " \"'marci\": 76164,\n",
              " \"otis's\": 52330,\n",
              " 'thanking': 23387,\n",
              " 'maude': 16019,\n",
              " 'extensions': 34759,\n",
              " 'ameteurish': 52332,\n",
              " \"commender's\": 52333,\n",
              " 'agricultural': 27661,\n",
              " 'convincingly': 4518,\n",
              " 'fueled': 17639,\n",
              " 'mahattan': 54014,\n",
              " \"paris's\": 40952,\n",
              " 'vulkan': 52336,\n",
              " 'stapes': 52337,\n",
              " 'odysessy': 52338,\n",
              " 'harmon': 12259,\n",
              " 'surfing': 4252,\n",
              " 'halloran': 23494,\n",
              " 'unbelieveably': 49580,\n",
              " \"'offed'\": 52339,\n",
              " 'quadrant': 30607,\n",
              " 'inhabiting': 19510,\n",
              " 'nebbish': 34760,\n",
              " 'forebears': 40953,\n",
              " 'skirmish': 34761,\n",
              " 'ocassionally': 52340,\n",
              " \"'resist\": 52341,\n",
              " 'impactful': 21928,\n",
              " 'spicier': 52342,\n",
              " 'touristy': 40954,\n",
              " \"'football'\": 52343,\n",
              " 'webpage': 40955,\n",
              " 'exurbia': 52345,\n",
              " 'jucier': 52346,\n",
              " 'professors': 14901,\n",
              " 'structuring': 34762,\n",
              " 'jig': 30608,\n",
              " 'overlord': 40956,\n",
              " 'disconnect': 25261,\n",
              " 'sniffle': 82201,\n",
              " 'slimeball': 40957,\n",
              " 'jia': 40958,\n",
              " 'milked': 16828,\n",
              " 'banjoes': 40959,\n",
              " 'jim': 1237,\n",
              " 'workforces': 52348,\n",
              " 'jip': 52349,\n",
              " 'rotweiller': 52350,\n",
              " 'mundaneness': 34763,\n",
              " \"'ninja'\": 52351,\n",
              " \"dead'\": 11040,\n",
              " \"cipriani's\": 40960,\n",
              " 'modestly': 20608,\n",
              " \"professor'\": 52352,\n",
              " 'shacked': 40961,\n",
              " 'bashful': 34764,\n",
              " 'sorter': 23388,\n",
              " 'overpowering': 16120,\n",
              " 'workmanlike': 18521,\n",
              " 'henpecked': 27662,\n",
              " 'sorted': 18522,\n",
              " \"jōb's\": 52354,\n",
              " \"'always\": 52355,\n",
              " \"'baptists\": 34765,\n",
              " 'dreamcatchers': 52356,\n",
              " \"'silence'\": 52357,\n",
              " 'hickory': 21929,\n",
              " 'fun\\x97yet': 52358,\n",
              " 'breakumentary': 52359,\n",
              " 'didn': 15496,\n",
              " 'didi': 52360,\n",
              " 'pealing': 52361,\n",
              " 'dispite': 40962,\n",
              " \"italy's\": 25262,\n",
              " 'instability': 21930,\n",
              " 'quarter': 6539,\n",
              " 'quartet': 12608,\n",
              " 'padmé': 52362,\n",
              " \"'bleedmedry\": 52363,\n",
              " 'pahalniuk': 52364,\n",
              " 'honduras': 52365,\n",
              " 'bursting': 10786,\n",
              " \"pablo's\": 41465,\n",
              " 'irremediably': 52367,\n",
              " 'presages': 40963,\n",
              " 'bowlegged': 57832,\n",
              " 'dalip': 65183,\n",
              " 'entering': 6260,\n",
              " 'newsradio': 76172,\n",
              " 'presaged': 54150,\n",
              " \"giallo's\": 27663,\n",
              " 'bouyant': 40964,\n",
              " 'amerterish': 52368,\n",
              " 'rajni': 18523,\n",
              " 'leeves': 30610,\n",
              " 'macauley': 34767,\n",
              " 'seriously': 612,\n",
              " 'sugercoma': 52369,\n",
              " 'grimstead': 52370,\n",
              " \"'fairy'\": 52371,\n",
              " 'zenda': 30611,\n",
              " \"'twins'\": 52372,\n",
              " 'realisation': 17640,\n",
              " 'highsmith': 27664,\n",
              " 'raunchy': 7817,\n",
              " 'incentives': 40965,\n",
              " 'flatson': 52374,\n",
              " 'snooker': 35097,\n",
              " 'crazies': 16829,\n",
              " 'crazier': 14902,\n",
              " 'grandma': 7094,\n",
              " 'napunsaktha': 52375,\n",
              " 'workmanship': 30612,\n",
              " 'reisner': 52376,\n",
              " \"sanford's\": 61306,\n",
              " '\\x91doña': 52377,\n",
              " 'modest': 6108,\n",
              " \"everything's\": 19153,\n",
              " 'hamer': 40966,\n",
              " \"couldn't'\": 52379,\n",
              " 'quibble': 13001,\n",
              " 'socking': 52380,\n",
              " 'tingler': 21931,\n",
              " 'gutman': 52381,\n",
              " 'lachlan': 40967,\n",
              " 'tableaus': 52382,\n",
              " 'headbanger': 52383,\n",
              " 'spoken': 2847,\n",
              " 'cerebrally': 34768,\n",
              " \"'road\": 23490,\n",
              " 'tableaux': 21932,\n",
              " \"proust's\": 40968,\n",
              " 'periodical': 40969,\n",
              " \"shoveller's\": 52385,\n",
              " 'tamara': 25263,\n",
              " 'affords': 17641,\n",
              " 'concert': 3249,\n",
              " \"yara's\": 87955,\n",
              " 'someome': 52386,\n",
              " 'lingering': 8424,\n",
              " \"abraham's\": 41511,\n",
              " 'beesley': 34769,\n",
              " 'cherbourg': 34770,\n",
              " 'kagan': 28624,\n",
              " 'snatch': 9097,\n",
              " \"miyazaki's\": 9260,\n",
              " 'absorbs': 25264,\n",
              " \"koltai's\": 40970,\n",
              " 'tingled': 64027,\n",
              " 'crossroads': 19511,\n",
              " 'rehab': 16121,\n",
              " 'falworth': 52389,\n",
              " 'sequals': 52390,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "index_from = 3\n",
        "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCi_QIzJDKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f3155d-99fb-450b-db13-18ff2cae3d72"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "imdb_word_index['simpsonian']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNfUSjwQSJTT",
        "outputId": "d3d998ad-b878-444c-b8c4-eb0365497bb2"
      },
      "source": [
        "imdb_word_index['the']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UkZwHiJDKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996d9993-61f6-4416-a2c6-04ab5fc5ec87"
      },
      "source": [
        "# View an input sentence\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " \"redford's\",\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " \"norman's\",\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'retail',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'congratulations',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " \"part's\",\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'praising',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2ID8wRJDKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e6a944-c9bd-4bc7-e387-0743a0348512"
      },
      "source": [
        "# Get the sentiment value\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662a89a4-e7b1-4d79-ec02-84780871e06e"
      },
      "source": [
        "# Load the imdb data set\n",
        "import tensorflow.keras.datasets.imdb as imdb  \n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWULtJ7CJDKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b9b3e5-0ef4-4a55-ccd3-ba81562d6f79"
      },
      "source": [
        "# Inspect the input data shape\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, \n",
        "                                                               maxlen=300,\n",
        "                                                               padding = 'post',\n",
        "                                                               truncating = 'pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNPiMGwDJDKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6581f298-7335-4b1d-bfca-61916c497e5b"
      },
      "source": [
        "# Inspect the output data shape\n",
        "padded_x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo"
      },
      "source": [
        "# Import numpy \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LjX9QaJDKr"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "padded_x_train = np.expand_dims(padded_x_train, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt"
      },
      "source": [
        "# Create a Masking layer \n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
        "masking_layer = tf.keras.layers.Masking(mask_value=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuStn9s0JDK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e757f2-5bc2-42ed-9122-aad71b367b42"
      },
      "source": [
        "# Look at the dataset\n",
        "masked_x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
              "array([[[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [2.200e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.940e+02],\n",
              "        [1.153e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [4.700e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.100e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.446e+03],\n",
              "        [7.079e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.700e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54DVLx4JDK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde0ab0a-35c3-496b-d86a-1f635af36d8d"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "masked_x_train._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "embedding_layer = Embedding(input_dim= 501, output_dim= 16) ## input_dim ==> # de tokens unicos.\n",
        "## output_dim ===> Tamaño de salida de la incrustacion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3B6HamJDLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b75b086-73c9-449d-99b1-ac7252bac74f"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "sequence_of_indices = tf.constant([[0], [1], [5], [500]])\n",
        "sequence_of_enbeddings = embedding_layer(sequence_of_indices)\n",
        "sequence_of_enbeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1, 16), dtype=float32, numpy=\n",
              "array([[[-0.00841339, -0.01832383,  0.03059975,  0.02026807,\n",
              "          0.01093792,  0.04255858, -0.00644926,  0.03476242,\n",
              "         -0.02709929,  0.01129743,  0.00701647,  0.02505788,\n",
              "         -0.0477317 , -0.02693535,  0.00186253,  0.01532043]],\n",
              "\n",
              "       [[ 0.00584067, -0.04114791, -0.04375951,  0.03260935,\n",
              "          0.03198001,  0.04318989, -0.00619566,  0.04542394,\n",
              "         -0.03785105, -0.02442619,  0.0399171 , -0.0060304 ,\n",
              "         -0.00819776,  0.00735227,  0.00919287, -0.03064154]],\n",
              "\n",
              "       [[-0.02390938,  0.02595652,  0.04382369, -0.01568152,\n",
              "          0.01641393, -0.03983147, -0.02573901, -0.03339324,\n",
              "         -0.0324445 , -0.01911904,  0.01047386, -0.0315086 ,\n",
              "          0.04840511, -0.03433235, -0.01589452, -0.03575413]],\n",
              "\n",
              "       [[-0.0398968 ,  0.00725944, -0.04782904, -0.01470246,\n",
              "          0.00147451, -0.03950337, -0.03707511, -0.01571579,\n",
              "          0.03039405, -0.03858818, -0.00352301,  0.00763027,\n",
              "         -0.03854365, -0.04119593, -0.04156794,  0.00868303]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualmsaPpJDLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c477064c-cea7-493b-d01a-4f83585f81ee"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "embedding_layer.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.00841339, -0.01832383,  0.03059975, ..., -0.02693535,\n",
              "          0.00186253,  0.01532043],\n",
              "        [ 0.00584067, -0.04114791, -0.04375951, ...,  0.00735227,\n",
              "          0.00919287, -0.03064154],\n",
              "        [-0.0349348 ,  0.03411356, -0.0471931 , ...,  0.01179751,\n",
              "          0.0093231 ,  0.04486782],\n",
              "        ...,\n",
              "        [-0.02728601, -0.04559796,  0.0387359 , ...,  0.02100025,\n",
              "         -0.03883427, -0.04302606],\n",
              "        [-0.01127176,  0.03402125,  0.00362192, ..., -0.01768498,\n",
              "         -0.04137632, -0.03373246],\n",
              "        [-0.0398968 ,  0.00725944, -0.04782904, ..., -0.04119593,\n",
              "         -0.04156794,  0.00868303]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wadlt3AJDLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab96829-d5de-4aa8-f8fa-5991f816a6f5"
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "embedding_layer.get_weights()[0][14, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02313194, -0.00394516, -0.01146644,  0.0086808 , -0.03941226,\n",
              "        0.00733865,  0.03787471,  0.00136333,  0.0393456 ,  0.00617988,\n",
              "        0.04865327,  0.01707424, -0.04474937, -0.00030953, -0.00064756,\n",
              "        0.03249541], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "masking_embedding_layer = Embedding(input_dim= 501, output_dim=16, mask_zero= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc1zx6A-H6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d920e58-996d-462a-a0ad-d5447e6850dc"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
        "masked_sequence_of_embeddings._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=bool, numpy=\n",
              "array([[False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3TCoTAu00"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKYrlepAxPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9af769-4e7d-4b07-aa7b-5c3a0c44f173"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de39aa68-ee2e-4f51-a27f-e0cff1616e4b"
      },
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cb16fb-02ed-4cc8-f65c-7aa305889489"
      },
      "source": [
        "# Get the word index\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquirCA8BS99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c332ef-65bf-4404-a984-6e2ed64cbd36"
      },
      "source": [
        "# View the first dataset example sentence\n",
        "[inv_imdb_word_index[index] for index in x_train[100] if index>2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'and',\n",
              " 'have',\n",
              " 'everything',\n",
              " 'that',\n",
              " \"he's\",\n",
              " 'made',\n",
              " 'on',\n",
              " 'dvd',\n",
              " 'except',\n",
              " 'for',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'the',\n",
              " '2',\n",
              " 'hour',\n",
              " 'twin',\n",
              " 'peaks',\n",
              " 'movie',\n",
              " 'so',\n",
              " 'when',\n",
              " 'i',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'this',\n",
              " 'i',\n",
              " 'immediately',\n",
              " 'grabbed',\n",
              " 'it',\n",
              " 'and',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'drawn',\n",
              " 'black',\n",
              " 'and',\n",
              " 'white',\n",
              " 'cartoons',\n",
              " 'that',\n",
              " 'are',\n",
              " 'loud',\n",
              " 'and',\n",
              " 'foul',\n",
              " 'mouthed',\n",
              " 'and',\n",
              " 'unfunny',\n",
              " 'maybe',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " \"what's\",\n",
              " 'good',\n",
              " 'but',\n",
              " 'maybe',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'crap',\n",
              " 'that',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'public',\n",
              " 'under',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'few',\n",
              " 'bucks',\n",
              " 'too',\n",
              " 'let',\n",
              " 'me',\n",
              " 'make',\n",
              " 'it',\n",
              " 'clear',\n",
              " 'that',\n",
              " 'i',\n",
              " \"didn't\",\n",
              " 'care',\n",
              " 'about',\n",
              " 'the',\n",
              " 'foul',\n",
              " 'language',\n",
              " 'part',\n",
              " 'but',\n",
              " 'had',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'because',\n",
              " 'my',\n",
              " 'neighbors',\n",
              " 'might',\n",
              " 'have',\n",
              " 'all',\n",
              " 'in',\n",
              " 'all',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'highly',\n",
              " 'disappointing',\n",
              " 'release',\n",
              " 'and',\n",
              " 'may',\n",
              " 'well',\n",
              " 'have',\n",
              " 'just',\n",
              " 'been',\n",
              " 'left',\n",
              " 'in',\n",
              " 'the',\n",
              " 'box',\n",
              " 'set',\n",
              " 'as',\n",
              " 'a',\n",
              " 'curiosity',\n",
              " 'i',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'you',\n",
              " \"don't\",\n",
              " 'spend',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " '2',\n",
              " 'out',\n",
              " 'of',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUfv9kjJDL1"
      },
      "source": [
        "# Get the maximum token value\n",
        "max_index_value = max(imdb_word_index.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "                    Embedding(input_dim= max_index_value+1, output_dim= embedding_dim, mask_zero=False), \n",
        "                    GlobalAveragePooling1D(),\n",
        "                    Dense(units=1, activation='sigmoid') ## Proba de que la review sea positiva\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "review_sequence = tf.keras.Input((None, ))\n",
        "embedding_sequence = Embedding(input_dim=max_index_value+1, output_dim=embedding_dim)(review_sequence)\n",
        "average_embedding = GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_probability = Dense(units=1, activation='sigmoid')(average_embedding)\n",
        "\n",
        "model = tf.keras.models.Model(inputs = review_sequence, outputs = positive_probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6oaEvTCKxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876c0469-078b-4f90-a30a-8429edced4cc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR-O7wGJDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bea6ef8-74a1-446e-a5e0-042616606ed2"
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 10s 8ms/step - loss: 0.6900 - accuracy: 0.5605 - val_loss: 0.6849 - val_accuracy: 0.6109\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6734 - accuracy: 0.6756 - val_loss: 0.6554 - val_accuracy: 0.7281\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6350 - accuracy: 0.7480 - val_loss: 0.6091 - val_accuracy: 0.7453\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5857 - accuracy: 0.7874 - val_loss: 0.5612 - val_accuracy: 0.7812\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5378 - accuracy: 0.8104 - val_loss: 0.5179 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ind0d_gvJDMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "dda39ea4-0678-482d-d1ff-0192828c4864"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open(path.join('/content/drive/MyDrive/Course_2 Customising your models with Tensoflow 2/Week3/projector', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('/content/drive/MyDrive/Course_2 Customising your models with Tensoflow 2/Week3/projector', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouh-qYss_9XA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
        "\n",
        "simplernn_layer = SimpleRNN(units= 16) ## Solo devuelven la secuencia final, no todas las del proceso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YJUyrEJDMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114ce214-b964-4913-d35b-5230f7e5f66e"
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "import tensorflow as tf\n",
        "sequence = tf.constant([[[1.,1.], [2.,2.], [56., -100.]]])\n",
        "layer_output = simplernn_layer(sequence)\n",
        "layer_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[ 1.       , -1.       , -1.       ,  1.       ,  1.       ,\n",
              "         0.9989687, -1.       , -1.       , -0.6543946, -1.       ,\n",
              "        -1.       ,  1.       ,  1.       ,  1.       , -1.       ,\n",
              "         1.       ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAtycIpH1aA"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f3f306-cc93-4229-8375-2b57d1016464"
      },
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01962bdc-0047-4285-ed75-741dfb43d0e5"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ"
      },
      "source": [
        "# Get the maximum index value\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "model = Sequential([\n",
        "                    Embedding(input_dim = max_index_value+1, output_dim = embedding_dim, mask_zero = True),\n",
        "                    LSTM(16),\n",
        "                    Dense(1, activation = 'sigmoid')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216PeHZFJDMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35de68f-13d1-4273-f529-c92ccb8f3bd8"
      },
      "source": [
        "# Fit the model and save its training history\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "536/536 [==============================] - 310s 571ms/step - loss: 0.4463 - accuracy: 0.7870 - val_loss: 0.3292 - val_accuracy: 0.8605\n",
            "Epoch 2/3\n",
            "536/536 [==============================] - 302s 563ms/step - loss: 0.2321 - accuracy: 0.9117 - val_loss: 0.2917 - val_accuracy: 0.8797\n",
            "Epoch 3/3\n",
            "536/536 [==============================] - 301s 562ms/step - loss: 0.1624 - accuracy: 0.9432 - val_loss: 0.3386 - val_accuracy: 0.8612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a9802c68-2cdc-45d9-d6e8-122da860f8a2"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88864a1-a859-4910-ee29-dbfaf479945d"
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "inv_imdb_word_index = {value:key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[0] if index > 2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['please',\n",
              " 'give',\n",
              " 'this',\n",
              " 'one',\n",
              " 'a',\n",
              " 'miss',\n",
              " 'br',\n",
              " 'br',\n",
              " 'and',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cast',\n",
              " 'rendered',\n",
              " 'terrible',\n",
              " 'performances',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " 'how',\n",
              " 'michael',\n",
              " 'madison',\n",
              " 'could',\n",
              " 'have',\n",
              " 'allowed',\n",
              " 'this',\n",
              " 'one',\n",
              " 'on',\n",
              " 'his',\n",
              " 'plate',\n",
              " 'he',\n",
              " 'almost',\n",
              " 'seemed',\n",
              " 'to',\n",
              " 'know',\n",
              " 'this',\n",
              " \"wasn't\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'work',\n",
              " 'out',\n",
              " 'and',\n",
              " 'his',\n",
              " 'performance',\n",
              " 'was',\n",
              " 'quite',\n",
              " 'so',\n",
              " 'all',\n",
              " 'you',\n",
              " 'madison',\n",
              " 'fans',\n",
              " 'give',\n",
              " 'this',\n",
              " 'a',\n",
              " 'miss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a141fbfb-69f4-47fe-da4a-01f8964dd96c"
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "model.predict(x_test[None, 0, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06518344]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc876674-e0c7-4afa-ced6-88031fa28420"
      },
      "source": [
        "# Get the corresponding label\n",
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06LdJiXKRt9"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA8JlQVKRuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6b2c20-699a-4c73-c66b-d2eacafd248a"
      },
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=5000, maxlen= 250)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iBFGx9_KRuD"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lcV0UGKRuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b253c10-30cd-4193-ca88-a14967b806fb"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "imdb_word_index = get_imdb_word_index(num_words=5000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "enbedding_dim = 16"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Embedding, Bidirectional\n",
        "\n",
        "model = Sequential([\n",
        "                    Embedding(input_dim=max_index_value +1, output_dim=enbedding_dim, mask_zero=True),\n",
        "                    LSTM(units=32, return_sequences=True),\n",
        "                    LSTM(32, return_sequences=False),\n",
        "                    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "model = Sequential([\n",
        "                    Embedding(input_dim=max_index_value +1, output_dim=enbedding_dim, mask_zero=True),\n",
        "                    Bidirectional(layer = LSTM(units = 8), merge_mode='sum',\n",
        "                                  backward_layer = GRU(8, go_backwards=True)),\n",
        "                    Dense(8, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "model = Sequential([\n",
        "                    Embedding(input_dim=max_index_value+1, output_dim=enbedding_dim),\n",
        "                    Bidirectional(layer=LSTM(8, return_sequences=True), merge_mode='concat'),\n",
        "                    GRU(units=8, return_sequences= False),\n",
        "                    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e065bf0f-b00c-4c36-deab-38ed2a8a11e5"
      },
      "source": [
        "# Train the model, saving its history\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "536/536 [==============================] - 30s 37ms/step - loss: 0.4403 - accuracy: 0.7910 - val_loss: 0.3432 - val_accuracy: 0.8582\n",
            "Epoch 2/3\n",
            "536/536 [==============================] - 19s 36ms/step - loss: 0.2511 - accuracy: 0.9054 - val_loss: 0.2990 - val_accuracy: 0.8751\n",
            "Epoch 3/3\n",
            "536/536 [==============================] - 19s 35ms/step - loss: 0.1911 - accuracy: 0.9306 - val_loss: 0.3547 - val_accuracy: 0.8655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "26aa943f-0129-4691-9abb-7bbb28e95574"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPTaZNSzrCJC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}